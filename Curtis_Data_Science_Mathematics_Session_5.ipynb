{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Mathematics\n",
    "# Statistical Inference\n",
    "# In-Class Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a p-value for our data set.  First, let's import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import our data set.  You need to specify the absolute path of the data set (Dataset_Session5.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r'Dataset_Session5.csv' #Specify absolute path here.\n",
    "data = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the data we want in the correct format: a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0614 0.0913 0.0368 0.0213 0.0098]\n"
     ]
    }
   ],
   "source": [
    "data_series = np.array(list(data['Similarity Metric (0.00-1.00)']))\n",
    "print(data_series[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and standard deviation\n",
    "m = np.average(data_series)\n",
    "# checking mean\n",
    "m_test = np.sum(data_series)/len(data_series)\n",
    "\n",
    "sd = np.std(data_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the values in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07577999999999999\n",
      "0.07577999999999999\n",
      "0.14518890774895077\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(m_test)\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, does it look like our value on 18 March 2018 is much different from the mean?\n",
    "\n",
    "We know that on 18 March 2018, our value is 0.8965.  We are performing a one-sample t-test in this case to see if our value at that date is anomalous.  We will take that sample to be the \"population mean,\" in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)\tWhat is your null hypothesis?  Explain what rejection of the null hypothesis means in terms of statistical inference.\n",
    "\n",
    "The null hypothesis is the layout of the data as if it were laid out according to chance according to a Gaussian distribution. Thus rejecting the null hypothesis means our statistical analysis is significant with meaning and not just as if it were drawing upon random chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = 0.8965"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's calculate our t statistic and our two-tailed p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-43.41977659265283\n"
     ]
    }
   ],
   "source": [
    "# calculating t statistic by hand using Python\n",
    "# t=(x ̅-μ_0)/(s⁄√n) n is n-1 because of being a small sample size\n",
    "t = (m - pop_mean)/(sd/np.sqrt(len(data_series)-1))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Are you able to detect an anomalous event on 18 March 2018, given the above data set, and assuming a type I error rate of 5%?  Explain why or why not.\n",
    "\n",
    "With 60 data inputs, our degrees of freedom is 59 (60-1). According to the chart from class, the critical value is 2.000, so the t statistic being so far separate from that critical value clearly shows an anomaly. We have to check that our mapping of this data beats the null hypothesis (which is the next part of this assignment in determining the p-value), before saying it will find other anamolous events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_1samp(data_series, pop_mean, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic: -43.41977659265283\n",
      "p-value: 1.749492641970814e-46\n"
     ]
    }
   ],
   "source": [
    "print('t statistic: {}'.format(t))\n",
    "print('p-value: {}'.format(float(p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we reject the null hypothesis?\n",
    "\n",
    "Yes we reject the null hypothesis, p-value is miniscule and would permit %99 probability of correlation with the size of the dataset given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d)\tCalculate by hand again assuming a type I error rate of 1%.  What happens to the critical value of t?  Intuitively, why is this the case?  Does this change impact your conclusion?\n",
    "\n",
    "Critical value of t looking at the table goes up to 2.660 with a %1 type I error rate. This makes sense as going according to the normal distribution, as you get closer to the center with a smaller range, the range of a random data point should grow slightly to compensate for random chance. This is similar to the Confidence Index we did in class, or the increasing *z values. It does not impact our conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now save your output.  Go to File -> Print Preview and save your final output as a PDF.  Turn in to your Instructor, along with any additional sheets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
